# Architecture & Design

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ROS2 Multi-Robot Recorder Dashboard              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                  â–¼                  â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Recorder â”‚        â”‚ Storage â”‚      â”‚Dashboard â”‚
   â”‚(ROS2)   â”‚        â”‚ (WAL)   â”‚      â”‚ (egui)   â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Sync Daemon  â”‚
           â”‚(background)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ S3 Cloud   â”‚
            â”‚  Bucket    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Core Modules

### 1. Recorder (`recorder.rs`)

**Purpose**: Subscribe to ROS2 topics and collect messages

**Design**:
- Conditional compilation: `#[cfg(feature = "ros2")]` for real ROS2 integration
- Falls back to mock recorder when ROS2 unavailable
- Maintains `RecorderState` with atomic message counter
- Async task spawned on startup

**Key Functions**:
```rust
pub fn start_recorder(storage: Storage, cfg: AppConfig) -> JoinHandle<()>
```

**ROS2 Integration** (when feature enabled):
- Creates r2r context for DDS access
- Discovers topics via graph API: `graph.get_topic_names_and_types()`
- Subscribes to each topic dynamically
- Spins node event loop with 100ms timeout
- Calls `storage.append_record()` for each message

**Mock Mode**:
- Simulates 4 topics: `/sensor/lidar`, `/tf`, `/odometry`, `/diagnostics`
- Records 2 robots: `robot1`, `robot2`
- 50 Hz simulation rate

### 2. Storage (`storage.rs`)

**Purpose**: Crash-safe recording with write-ahead logging (WAL)

**Design Principles**:
- **Append-only**: All writes are sequential appends to segment files
- **Atomic commits**: Each record has framing, metadata, CRC32, and fsync
- **Crash recovery**: Checkpoint manifests enable resume from last good state
- **Segment rotation**: Fixed-size segments (16 MiB default) for manageability

**Record Format**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Magic   â”‚ Meta Len  â”‚ Metadata â”‚ Payload Length  â”‚  Payload   â”‚
â”‚(0xDEAD   â”‚  (u32 LE) â”‚ (JSON)   â”‚ & CRC32 & ts    â”‚ (bytes)    â”‚
â”‚  BEEF)   â”‚           â”‚          â”‚                 â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  4 bytes     4 bytes   variable    JSON metadata     variable
```

**Metadata JSON**:
```json
{
  "magic": 3735928559,
  "timestamp": 1729069234567,
  "topic": "/sensor/lidar",
  "namespace": "robot1",
  "payload_len": 2048,
  "payload_crc32": "0xabcd1234"
}
```

**Recovery Algorithm**:
1. Load `.checkpoint` file (JSON with `current_segment` number)
2. Open that segment file
3. Read records sequentially
4. If magic != 0xDEADBEEF or CRC mismatch, stop (corrupted tail)
5. Replay all valid records to in-memory buffer
6. Resume from next segment

**Methods**:
- `new(cfg)` - Initialize, recover from checkpoint
- `append_record(topic, ns, data, ts)` - Write with fsync
- `rotate_segment()` - Save checkpoint, move to next segment
- `list_segments()` - Get all pending segments
- `segment_checksum(path)` - SHA256 of segment file
- `replay_segment(path)` - Read all records from segment

**Thread Safety**:
- Uses `tokio::sync::Mutex` for inner state
- Segment rotation is atomic (checkpoint write before increment)

### 3. Sync Daemon (`sync.rs`)

**Purpose**: Background upload to cloud with resumable state

**Design**:
- Independent background task
- Maintains upload queue (Vec<UploadState>)
- Exponential backoff on failures
- Persisted resume state for each segment

**Upload Flow**:
```
Segment File (16 MB)
       â”‚
       â–¼
    Chunker (chunks = 16 segments @ 1 MB each)
       â”‚
       â”œâ”€â–º Chunk 0 (1 MB) â”€â”€SHA256â”€â”€â–º sha256_0
       â”œâ”€â–º Chunk 1 (1 MB) â”€â”€SHA256â”€â”€â–º sha256_1
       â””â”€â–º Chunk N (...)  â”€â”€SHA256â”€â”€â–º sha256_N
       â”‚
       â–¼
   Upload Queue (persisted to disk)
       â”‚
       â”œâ”€â–º { segment, sha256, [uploaded_chunks], timestamp }
       â””â”€â–º ...
       â”‚
       â–¼
   S3 Multipart Upload (mock impl in v0.1.0)
```

**Resume State** (JSON):
```json
{
  "segment_path": "./data/segment-0.log",
  "segment_sha256": "abc123...",
  "chunks_uploaded": [
    { "chunk_index": 0, "sha256": "def456...", "upload_id": "..." },
    { "chunk_index": 1, "sha256": "ghi789...", "upload_id": "..." }
  ],
  "timestamp": 1729069234567
}
```

**Backoff Strategy**:
- Retry 1: 2 seconds
- Retry 2: 4 seconds
- Retry 3: 8 seconds
- ...
- Retry 7: 128 seconds (capped at 120)

**Methods**:
- `new(storage, config)` - Initialize daemon
- `get_status()` - Return current SyncStatus
- `queue_segment(path)` - Add to upload queue
- `sync_loop(max_retries)` - Main background loop
- `process_next_upload()` - Handle one segment

**Status Tracking**:
```rust
pub struct SyncStatus {
    pub is_syncing: bool,
    pub last_sync_time: Option<u128>,
    pub upload_errors: usize,
    pub total_segments_synced: usize,
}
```

### 4. Dashboard (`dashboard.rs`)

**Purpose**: Live UI for monitoring and control

**UI Layout** (egui):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ROS2 Multi-Robot Recorder & Dashboard                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recording: â— ACTIVE  â”‚  Rate: 150.5 Hz  â”‚  Storage: 234.2 MB  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Select Robot: [robot1 â–¼]                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recording Controls                                    â”‚
â”‚ [â–¶ Start] [â¸ Pause] [â¹ Stop] | [â†‘ Sync] [ğŸ“Š Export] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Sync Status                                           â”‚
â”‚ Status: Syncing...      Last Sync: 2 min ago         â”‚
â”‚ Upload Progress: [=====â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€] 65%              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Topics (20 active)                                    â”‚
â”‚ /sensor/lidar â—† 50 Hz                                â”‚
â”‚ /tf           â—† 100 Hz                               â”‚
â”‚ /odometry     â—† 25 Hz                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ System Diagnostics                                    â”‚
â”‚ CPU: 45%  â”‚  Memory: 1.2 GB  â”‚  Disk: 234/1000 GB    â”‚
â”‚ Network: â— Online  Latency: 12 ms                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Features**:
- Real-time metrics from mock data
- Responsive controls (30 FPS egui loop)
- Multi-robot selector
- Status polling with `ctx.request_repaint()`
- Future: Live graph integration with plotters crate

**Conditional Compilation**:
- `#[cfg(feature = "ui")]` for egui (macOS/Windows/Linux)
- Falls back to headless mode when UI feature disabled

### 5. Exporter (`exporter.rs`)

**Purpose**: ML-ready data export

**Supported Formats**:
- **Parquet**: Arrow2-based columnar format (future)
- **CSV**: Comma-separated values (future)
- **TFRecord**: TensorFlow record format (stub)
- **Numpy**: .npy binary format (stub)

**Manifest Generation**:
```json
{
  "export_id": "session_123-parquet",
  "format": "Parquet",
  "timestamp_utc": 1729069234567,
  "num_records": 50000,
  "topics": [
    {
      "topic": "/sensor/lidar",
      "message_type": "sensor_msgs/PointCloud2",
      "sample_count": 10000,
      "sample_rate_hz": 50.0
    }
  ]
}
```

**Methods**:
- `export_session(session_id, output_dir, format)` - Main export
- `export_to_parquet()` - Columnar format
- `export_to_csv()` - Row format
- `export_to_tfrecord()` - TensorFlow format
- `export_to_numpy()` - Numpy array format

### 6. Configuration (`config.rs`)

**Storage Config**:
- `path`: Local data directory
- `wal_segment_size`: Segment rotation threshold
- `compress`: Enable compression (future)
- `encryption`: Encryption mode (future)

**Sync Config**:
- `endpoint`: S3-compatible endpoint URL
- `bucket`: Cloud bucket name
- `chunk_size`: Upload chunk size (16 MiB default)
- `max_retries`: Exponential backoff retries

## Concurrency Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         main() tokio runtime            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  Recorder Task â—„â”€â”€â”                    â”‚
â”‚  (async)          â”‚  Arc<Storage>      â”‚
â”‚   - ROS2 loop     â”‚   (thread-safe)    â”‚
â”‚   - append_record â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”          â”‚
â”‚                  â”‚          â”‚          â”‚
â”‚  Sync Daemon Task         â”‚  Disk      â”‚
â”‚  (background)             â”‚  I/O       â”‚
â”‚   - queue check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  (async)   â”‚
â”‚   - upload                            â”‚
â”‚                                         â”‚
â”‚  Dashboard Task                        â”‚
â”‚  (blocking UI)                         â”‚
â”‚   - egui event loop                    â”‚
â”‚   - (blocks on UI exit)               â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Synchronization Primitives**:
- `Arc<Mutex<T>>` for shared state (Storage inner, SyncDaemon)
- `Arc<AtomicU64>` for message counters (non-blocking)
- `tokio::sync::Mutex` for async locks

## Error Handling

**Strategy**: All operations return `anyhow::Result<T>` with context

**Common Errors**:
- IO errors (disk full, permission denied)
- Serialization errors (JSON, frame parsing)
- Checksum mismatches (CRC32, SHA256)
- Network errors (timeout, unreachable)

**Propagation**:
```rust
match storage.append_record(...).await {
    Ok(_) => tracing::debug!("recorded"),
    Err(e) => {
        tracing::error!("record failed: {:#?}", e);
        // Continue or fail depending on policy
    }
}
```

## Performance Characteristics

| Metric | Target | Achieved |
|--------|--------|----------|
| Recording throughput | >100 MB/s | N/A (untested at scale) |
| WAL commit latency | <1 ms | fsync-limited (~1-2 ms on SSD) |
| Message overhead | <50 bytes | JSON metadata + framing |
| UI frame rate | 30 FPS | 30 FPS (egui) |
| Sync daemon CPU | <5% | N/A (mock impl) |
| Memory baseline | <100 MB | ~50 MB measured |

## Future Enhancements

### Short Term
- [ ] Real S3 multipart upload integration
- [ ] Parquet/CSV export with arrow2
- [ ] Prometheus metrics exporter
- [ ] AES-GCM encryption

### Medium Term
- [ ] Distributed recording (multiple recorders syncing to central)
- [ ] Time-series database (e.g., InfluxDB) integration
- [ ] Web dashboard (replace egui with web UI)
- [ ] Kubernetes deployment

### Long Term
- [ ] Machine learning inference pipeline
- [ ] Real-time anomaly detection
- [ ] Multi-site replication
- [ ] Commercial offering

---

**Last Updated**: 2025-10-27
**Version**: 0.1.0
